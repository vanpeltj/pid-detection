"""
DO NOT EDIT! THIS IS AN AUTOGENERATED FILE!!!!!
"""
import json
import uuid
import s3fs
from typing import Optional, Text, Annotated
import boto3
from datetime import datetime
from fastapi import UploadFile, File, Depends, HTTPException
from starlette.responses import FileResponse

from utils.enums import *
from core.api.sento_router import SentoRouter
from core.database.db import get_db
from core.config import settings
from schemas.pid_file import pid_file as Schemapid_file
from schemas.pid_file import pid_fileCreate as Schemapid_fileCreate
from schemas.pid_file import pid_fileUpdate as Schemapid_fileUpdate
from schemas.pid_file import pid_fileUpsert as Schemapid_fileUpsert
from schemas.job import jobCreate as Schemajob
from data.job import job
from data.pid_file import pid_file
from sqlalchemy.orm import Session
from sqlalchemy.ext.declarative import DeclarativeMeta as Model

from models.pid_file import pid_file as Modelpid_file
from core.api import _utils


s3_client = boto3.client("s3")
sqs_client = boto3.client("sqs")


def get_all_filter_function(file_uuid: str = None, project_id: Optional[int] = None):
    return {"file_uuid": file_uuid, "project_id": project_id}


get_all_filter_meta = {'file_uuid': {'condition': '==', 'column': 'file_uuid'},
                       'project_id': {'condition': '==', 'column': 'project_id'}}

model_router = SentoRouter(
    schema=Schemapid_file,
    db=get_db,
    prefix="pid_file",
    db_model=Modelpid_file,
    create_schema=Schemapid_fileCreate,
    update_schema=Schemapid_fileUpdate,
    upsert_schema=Schemapid_fileUpsert,
    get_all_filter_function=get_all_filter_function,
    get_all_filter_meta=get_all_filter_meta,
    create_one_callback=False,
    update_one_callback=False,
    delete_one_callback=False,
    delete_all_callback=False,
    unique_fields=['file_uuid'],
    delete_all_route=False,
)

def create_pid_processing_job(file_id: int ,project_id: int, s3_key: Text):

    job_db = job(
        name = "process_pid_file",
        type= "PROCESS_PID_FILE",
        status = "QUEUED",
        file_id = file_id,
        project_id = project_id,
        created_at=datetime.now(),
    ).save()


    queue_url = settings.PID_PROCESSING_QUEUE_URL
    message_body = {
        "action": "process_pid_files",
        "details": "Process PID files uploaded to S3",
        "s3_key" : s3_key,
        "job_id": job_db.id,
        "file_id": file_id
    }

    try:
        response = sqs_client.send_message(
            QueueUrl=queue_url,
            MessageBody=json.dumps(message_body)
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"SQS job creation failed: {str(e)}")

    return job_db



@model_router.post("/upload")
async def upload(project_id: int, file: UploadFile = File(...), db: Session = Depends(get_db)):


    file_name = file.filename
    bucket_name = "643553455790-eu-west-1-files"

    file_uuid = str(uuid.uuid4())
    print(f"File {file_name} with UUID {file_uuid} received for project {project_id} with file_type {file.content_type} with size {file.size} bytes")

    s3_key = f"uploads/pid_files/{file_uuid}/{file_name}"


    fs = s3fs.S3FileSystem(anon=False)


    try:
        await file.seek(0)  # Reset file pointer to the beginning
        contents = await file.read()
        s3_path = f"{bucket_name}/{s3_key}"
        with fs.open(s3_path, "wb") as f:
            f.write(contents)
        #s3_client.put_object(Bucket=bucket_name, Key=s3_key, Body=contents, ContentType="application/pdf")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"S3 upload failed: {str(e)}")


    db_model: Model = Modelpid_file(
        project_id=project_id,
        file_name=file_name,
        file_uuid=file_uuid,
        s3_key=s3_key,
        modified_on=_utils.get_modified_on()
    )

    db.add(db_model)
    db.commit()
    db.refresh(db_model)

    return db_model


@model_router.post("/process")
def process(file_id: int, db: Session = Depends(get_db)) :
    f = pid_file.from_id(file_id, db)
    if not f:
        raise HTTPException(status_code=404, detail="File not found")

    file_id = f.id
    project_id = f.project_id
    s3_key = f.s3_key

    job = create_pid_processing_job(file_id, project_id, s3_key)

    return job